{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def load_labeled_data(path):\n",
    "    states = []\n",
    "    actions = []\n",
    "    for f in os.listdir(path):\n",
    "        e_c = np.load(f'{path}/{f}')\n",
    "        states.append(e_c['states'])\n",
    "        actions.append(e_c['actions'])\n",
    "    return states, actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "states, actions = load_labeled_data('human_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 2, 300, 200)\n",
      "(24,)\n"
     ]
    }
   ],
   "source": [
    "print(states[0].shape)\n",
    "print(actions[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(states, actions):\n",
    "    def count_steps(actions):\n",
    "        s = 0\n",
    "        for a in actions:\n",
    "            s += a.size\n",
    "        return s\n",
    "    num_steps = count_steps(actions)\n",
    "    X_states = np.empty((num_steps, 4, 300, 200), dtype=np.single)\n",
    "    y_actions = np.empty((num_steps))\n",
    "    step = 0\n",
    "    for s,a in zip(states, actions):\n",
    "        length_try = a.size\n",
    "\n",
    "        X_states[step:step+length_try,0] = s[:,0]\n",
    "        X_states[step:step+length_try,1] = s[:,0]\n",
    "        X_states[step:step+length_try,2] = s[:,1]\n",
    "        X_states[step:step+length_try,3] = s[:,1]\n",
    "        y_actions[step:step+length_try] = a\n",
    "\n",
    "        step += length_try\n",
    "\n",
    "    return X_states, y_actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_states, y_actions = create_dataset(states, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "del states\n",
    "del actions\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3727, 4, 300, 200)\n",
      "(3727,)\n"
     ]
    }
   ],
   "source": [
    "print(X_states.shape)\n",
    "print(y_actions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3577920000\n"
     ]
    }
   ],
   "source": [
    "print(X_states.size * 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "for i in range(1):\n",
    "    im = Image.fromarray(X_states[0,i]*255)\n",
    "    im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    im = Image.fromarray(X_states[0,2+i]*255)\n",
    "    im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=4, out_channels=32, kernel_size=8, stride=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(5, stride=3),\n",
    "    nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(5, stride=3),\n",
    "    nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(5, stride=3),\n",
    "    nn.Flatten(start_dim=1),\n",
    "    nn.Linear(2560, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 4),\n",
    "    nn.Softmax(dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.empty((int(X_states.shape[0]*0.7),4,300,200), dtype=np.single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.permutation(X_states.shape[0])\n",
    "train_idx, test_idx = indices[:X_train.shape[0]], indices[X_train.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_states[train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del X_states\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# enc = OneHotEncoder().fit(y_actions[train_idx].reshape(-1,1))\n",
    "# y_train = enc.transform(y_actions[train_idx].reshape(-1,1)).toarray()\n",
    "# print(y_train.shape)\n",
    "\n",
    "# print(y_train[0])\n",
    "# print(y_actions[train_idx][0])\n",
    "\n",
    "# print(y_train[1])\n",
    "# print(y_actions[train_idx][1])\n",
    "y_train = y_actions[train_idx].copy()\n",
    "y_train[y_train == -1] = 2 # ignore unlabeled data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2537, 0.2431, 0.2647, 0.2385],\n",
      "        [0.2532, 0.2425, 0.2649, 0.2393],\n",
      "        [0.2536, 0.2439, 0.2643, 0.2383],\n",
      "        [0.2531, 0.2435, 0.2631, 0.2402],\n",
      "        [0.2533, 0.2446, 0.2628, 0.2392],\n",
      "        [0.2531, 0.2431, 0.2642, 0.2396],\n",
      "        [0.2536, 0.2427, 0.2644, 0.2394],\n",
      "        [0.2537, 0.2436, 0.2644, 0.2383],\n",
      "        [0.2526, 0.2434, 0.2635, 0.2405],\n",
      "        [0.2532, 0.2426, 0.2643, 0.2399],\n",
      "        [0.2530, 0.2437, 0.2639, 0.2393],\n",
      "        [0.2528, 0.2431, 0.2647, 0.2394],\n",
      "        [0.2529, 0.2425, 0.2652, 0.2394],\n",
      "        [0.2540, 0.2419, 0.2664, 0.2377],\n",
      "        [0.2522, 0.2428, 0.2639, 0.2411],\n",
      "        [0.2524, 0.2448, 0.2634, 0.2393]], grad_fn=<ReshapeAliasBackward0>)\n",
      "tensor([2, 2, 2, 2, 0, 0, 2, 2, 2, 0, 2, 2, 1, 1, 0, 3])\n",
      "[1,    32] loss: 1.384\n",
      "tensor([[0.2581, 0.2356, 0.2952, 0.2111],\n",
      "        [0.2559, 0.2385, 0.2903, 0.2153],\n",
      "        [0.2553, 0.2373, 0.2901, 0.2172],\n",
      "        [0.2570, 0.2383, 0.2902, 0.2145],\n",
      "        [0.2556, 0.2372, 0.2915, 0.2157],\n",
      "        [0.2555, 0.2376, 0.2918, 0.2151],\n",
      "        [0.2568, 0.2386, 0.2894, 0.2151],\n",
      "        [0.2564, 0.2398, 0.2879, 0.2159],\n",
      "        [0.2557, 0.2369, 0.2905, 0.2169],\n",
      "        [0.2568, 0.2393, 0.2880, 0.2159],\n",
      "        [0.2581, 0.2355, 0.2952, 0.2112],\n",
      "        [0.2556, 0.2380, 0.2919, 0.2145],\n",
      "        [0.2559, 0.2386, 0.2887, 0.2167],\n",
      "        [0.2557, 0.2401, 0.2882, 0.2160],\n",
      "        [0.2580, 0.2358, 0.2950, 0.2111],\n",
      "        [0.2563, 0.2381, 0.2899, 0.2157]], grad_fn=<ReshapeAliasBackward0>)\n",
      "tensor([2, 1, 0, 1, 2, 0, 0, 1, 0, 1, 2, 2, 2, 2, 2, 2])\n",
      "[1,    64] loss: 1.375\n",
      "tensor([[0.2561, 0.2256, 0.3501, 0.1682],\n",
      "        [0.2553, 0.2258, 0.3519, 0.1671],\n",
      "        [0.2550, 0.2228, 0.3572, 0.1650],\n",
      "        [0.2549, 0.2223, 0.3576, 0.1652],\n",
      "        [0.2545, 0.2248, 0.3528, 0.1680],\n",
      "        [0.2544, 0.2236, 0.3552, 0.1668],\n",
      "        [0.2563, 0.2247, 0.3526, 0.1664],\n",
      "        [0.2546, 0.2237, 0.3536, 0.1681],\n",
      "        [0.2549, 0.2232, 0.3565, 0.1655],\n",
      "        [0.2561, 0.2240, 0.3528, 0.1671],\n",
      "        [0.2548, 0.2251, 0.3510, 0.1692],\n",
      "        [0.2546, 0.2238, 0.3572, 0.1643],\n",
      "        [0.2556, 0.2248, 0.3520, 0.1675],\n",
      "        [0.2548, 0.2213, 0.3591, 0.1647],\n",
      "        [0.2544, 0.2245, 0.3526, 0.1685],\n",
      "        [0.2544, 0.2233, 0.3559, 0.1664]], grad_fn=<ReshapeAliasBackward0>)\n",
      "tensor([1, 2, 1, 2, 2, 2, 2, 0, 2, 0, 0, 1, 1, 1, 2, 2])\n",
      "[1,    96] loss: 1.360\n",
      "tensor([[0.2001, 0.1700, 0.5615, 0.0684],\n",
      "        [0.1969, 0.1668, 0.5693, 0.0670],\n",
      "        [0.1947, 0.1650, 0.5753, 0.0650],\n",
      "        [0.1957, 0.1662, 0.5716, 0.0665],\n",
      "        [0.1950, 0.1668, 0.5718, 0.0664],\n",
      "        [0.1999, 0.1721, 0.5580, 0.0701],\n",
      "        [0.1966, 0.1672, 0.5702, 0.0661],\n",
      "        [0.1935, 0.1643, 0.5776, 0.0646],\n",
      "        [0.1954, 0.1663, 0.5725, 0.0659],\n",
      "        [0.1972, 0.1691, 0.5665, 0.0672],\n",
      "        [0.1963, 0.1670, 0.5711, 0.0656],\n",
      "        [0.1970, 0.1676, 0.5675, 0.0679],\n",
      "        [0.1987, 0.1681, 0.5658, 0.0674],\n",
      "        [0.1974, 0.1680, 0.5676, 0.0670],\n",
      "        [0.1970, 0.1680, 0.5670, 0.0679],\n",
      "        [0.1962, 0.1672, 0.5713, 0.0654]], grad_fn=<ReshapeAliasBackward0>)\n",
      "tensor([2, 2, 2, 0, 0, 1, 1, 2, 1, 1, 2, 1, 0, 1, 0, 0])\n",
      "[1,   128] loss: 1.334\n",
      "tensor([[0.0970, 0.0846, 0.8040, 0.0145],\n",
      "        [0.0992, 0.0868, 0.7989, 0.0151],\n",
      "        [0.0888, 0.0779, 0.8211, 0.0122],\n",
      "        [0.0998, 0.0873, 0.7975, 0.0154],\n",
      "        [0.0994, 0.0872, 0.7980, 0.0154],\n",
      "        [0.0965, 0.0846, 0.8046, 0.0144],\n",
      "        [0.0985, 0.0861, 0.8004, 0.0150],\n",
      "        [0.1008, 0.0889, 0.7945, 0.0158],\n",
      "        [0.0992, 0.0869, 0.7986, 0.0152],\n",
      "        [0.0982, 0.0864, 0.8006, 0.0148],\n",
      "        [0.1021, 0.0904, 0.7914, 0.0161],\n",
      "        [0.0969, 0.0854, 0.8034, 0.0144],\n",
      "        [0.0961, 0.0838, 0.8060, 0.0142],\n",
      "        [0.1032, 0.0907, 0.7897, 0.0163],\n",
      "        [0.1017, 0.0896, 0.7927, 0.0160],\n",
      "        [0.0961, 0.0837, 0.8062, 0.0141]], grad_fn=<ReshapeAliasBackward0>)\n",
      "tensor([0, 2, 2, 2, 2, 2, 1, 0, 2, 2, 2, 1, 1, 0, 2, 1])\n",
      "[1,   160] loss: 1.283\n",
      "tensor([[0.0796, 0.0766, 0.8351, 0.0087],\n",
      "        [0.0772, 0.0745, 0.8399, 0.0084],\n",
      "        [0.0820, 0.0796, 0.8291, 0.0093],\n",
      "        [0.0867, 0.0838, 0.8190, 0.0105],\n",
      "        [0.0841, 0.0815, 0.8247, 0.0097],\n",
      "        [0.0833, 0.0802, 0.8269, 0.0096],\n",
      "        [0.0797, 0.0769, 0.8345, 0.0089],\n",
      "        [0.0795, 0.0769, 0.8348, 0.0088],\n",
      "        [0.0824, 0.0802, 0.8277, 0.0097],\n",
      "        [0.0792, 0.0767, 0.8353, 0.0088],\n",
      "        [0.0803, 0.0780, 0.8328, 0.0089],\n",
      "        [0.0840, 0.0812, 0.8249, 0.0099],\n",
      "        [0.0775, 0.0745, 0.8396, 0.0084],\n",
      "        [0.0776, 0.0748, 0.8392, 0.0084],\n",
      "        [0.0841, 0.0810, 0.8248, 0.0100],\n",
      "        [0.0844, 0.0821, 0.8236, 0.0099]], grad_fn=<ReshapeAliasBackward0>)\n",
      "tensor([2, 2, 2, 2, 0, 0, 2, 2, 2, 0, 2, 2, 1, 1, 0, 3])\n",
      "[2,    32] loss: 1.268\n",
      "tensor([[0.0535, 0.0457, 0.8972, 0.0036],\n",
      "        [0.0636, 0.0561, 0.8752, 0.0051],\n",
      "        [0.0632, 0.0556, 0.8760, 0.0052],\n",
      "        [0.0641, 0.0561, 0.8746, 0.0052],\n",
      "        [0.0627, 0.0551, 0.8772, 0.0051],\n",
      "        [0.0621, 0.0546, 0.8784, 0.0049],\n",
      "        [0.0656, 0.0578, 0.8712, 0.0054],\n",
      "        [0.0658, 0.0579, 0.8710, 0.0053],\n",
      "        [0.0648, 0.0563, 0.8736, 0.0053],\n",
      "        [0.0660, 0.0582, 0.8703, 0.0055],\n",
      "        [0.0537, 0.0458, 0.8969, 0.0036],\n",
      "        [0.0627, 0.0553, 0.8770, 0.0050],\n",
      "        [0.0651, 0.0575, 0.8719, 0.0055],\n",
      "        [0.0667, 0.0590, 0.8686, 0.0056],\n",
      "        [0.0535, 0.0457, 0.8972, 0.0036],\n",
      "        [0.0645, 0.0568, 0.8734, 0.0053]], grad_fn=<ReshapeAliasBackward0>)\n",
      "tensor([2, 1, 0, 1, 2, 0, 0, 1, 0, 1, 2, 2, 2, 2, 2, 2])\n",
      "[2,    64] loss: 1.249\n",
      "tensor([[0.0715, 0.0657, 0.8573, 0.0055],\n",
      "        [0.0696, 0.0647, 0.8605, 0.0052],\n",
      "        [0.0647, 0.0590, 0.8719, 0.0044],\n",
      "        [0.0668, 0.0614, 0.8670, 0.0048],\n",
      "        [0.0694, 0.0642, 0.8611, 0.0053],\n",
      "        [0.0694, 0.0639, 0.8615, 0.0053],\n",
      "        [0.0701, 0.0647, 0.8600, 0.0053],\n",
      "        [0.0691, 0.0634, 0.8624, 0.0052],\n",
      "        [0.0679, 0.0623, 0.8648, 0.0050],\n",
      "        [0.0702, 0.0643, 0.8602, 0.0053],\n",
      "        [0.0712, 0.0654, 0.8578, 0.0055],\n",
      "        [0.0674, 0.0626, 0.8651, 0.0049],\n",
      "        [0.0711, 0.0653, 0.8581, 0.0055],\n",
      "        [0.0670, 0.0611, 0.8670, 0.0049],\n",
      "        [0.0709, 0.0651, 0.8585, 0.0055],\n",
      "        [0.0689, 0.0631, 0.8628, 0.0052]], grad_fn=<ReshapeAliasBackward0>)\n",
      "tensor([1, 2, 1, 2, 2, 2, 2, 0, 2, 0, 0, 1, 1, 1, 2, 2])\n",
      "[2,    96] loss: 1.267\n",
      "tensor([[0.1003, 0.1208, 0.7696, 0.0093],\n",
      "        [0.0978, 0.1176, 0.7757, 0.0089],\n",
      "        [0.0950, 0.1148, 0.7820, 0.0083],\n",
      "        [0.0968, 0.1165, 0.7779, 0.0087],\n",
      "        [0.0962, 0.1168, 0.7784, 0.0087],\n",
      "        [0.1013, 0.1225, 0.7666, 0.0096],\n",
      "        [0.0971, 0.1178, 0.7764, 0.0086],\n",
      "        [0.0943, 0.1144, 0.7831, 0.0082],\n",
      "        [0.0961, 0.1168, 0.7785, 0.0086],\n",
      "        [0.0978, 0.1191, 0.7742, 0.0089],\n",
      "        [0.0963, 0.1170, 0.7783, 0.0084],\n",
      "        [0.0980, 0.1177, 0.7753, 0.0090],\n",
      "        [0.0989, 0.1189, 0.7732, 0.0090],\n",
      "        [0.0978, 0.1184, 0.7749, 0.0088],\n",
      "        [0.0977, 0.1180, 0.7754, 0.0089],\n",
      "        [0.0968, 0.1179, 0.7767, 0.0085]], grad_fn=<ReshapeAliasBackward0>)\n",
      "tensor([2, 2, 2, 0, 0, 1, 1, 2, 1, 1, 2, 1, 0, 1, 0, 0])\n",
      "[2,   128] loss: 1.297\n",
      "tensor([[0.0961, 0.1361, 0.7602, 0.0077],\n",
      "        [0.0985, 0.1388, 0.7546, 0.0081],\n",
      "        [0.0880, 0.1285, 0.7772, 0.0063],\n",
      "        [0.0989, 0.1391, 0.7538, 0.0082],\n",
      "        [0.0986, 0.1392, 0.7540, 0.0082],\n",
      "        [0.0958, 0.1361, 0.7605, 0.0076],\n",
      "        [0.0979, 0.1379, 0.7562, 0.0080],\n",
      "        [0.1001, 0.1410, 0.7503, 0.0085],\n",
      "        [0.0986, 0.1389, 0.7543, 0.0082],\n",
      "        [0.0974, 0.1386, 0.7560, 0.0079],\n",
      "        [0.1010, 0.1429, 0.7474, 0.0087],\n",
      "        [0.0963, 0.1375, 0.7586, 0.0077],\n",
      "        [0.0954, 0.1354, 0.7617, 0.0075],\n",
      "        [0.1023, 0.1437, 0.7452, 0.0089],\n",
      "        [0.1008, 0.1415, 0.7490, 0.0087],\n",
      "        [0.0956, 0.1356, 0.7613, 0.0075]], grad_fn=<ReshapeAliasBackward0>)\n",
      "tensor([0, 2, 2, 2, 2, 2, 1, 0, 2, 2, 2, 1, 1, 0, 2, 1])\n",
      "[2,   160] loss: 1.272\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    indices = np.random.permutation(X_train.shape[0])\n",
    "\n",
    "    for i in range(int(X_train.shape[0] / batch_size)):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs_batch = torch.from_numpy(X_train[batch_size * i: batch_size * (i+1)])\n",
    "        labels_batch = torch.from_numpy(y_train[batch_size * i: batch_size * (i+1)]).long()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs_batch).reshape((batch_size,4))\n",
    "        loss = criterion(outputs, labels_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 32 == 31:    # print every 200 mini-batches\n",
    "            print(outputs)\n",
    "            print(labels_batch)\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 32:.3f}')\n",
    "            running_loss = 0.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
